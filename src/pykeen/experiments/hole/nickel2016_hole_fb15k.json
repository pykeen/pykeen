{
  "metadata": {
    "title": "Learn FB15K Data Set with HolE as described by Nickel et al., 2016",
    "comments": " We use same setting as for WN18 (based on https://github.com/mnick/holographic-embeddings/blob/c2db6e1554e671ab8e6acace78ec1fd91d6a4b90/run_hole_wn18.sh, however it is not sure whether this is the correct setting) since we couldn't find the setting for FB15k. The evaluation uses the non-deterministic rank, as seen from https://github.com/mnick/holographic-embeddings/blob/c2db6e1554e671ab8e6acace78ec1fd91d6a4b90/kg/base.py#L198."
  },
  "pipeline": {
    "dataset": "fb15k",
    "model": "HolE",
    "model_kwargs": {
      "embedding_dim": 150
    },
    "optimizer": "AdaGrad",
    "optimizer_kwargs": {
      "lr": 0.1
    },
    "loss": "MarginRankingLoss",
    "loss_kwargs": {
      "reduction": "mean",
      "margin": 0.2
    },
    "training_loop": "SLCWA",
    "negative_sampler": "basic",
    "negative_sampler_kwargs": {
      "num_negs_per_pos": 1
    },
    "training_kwargs": {
      "num_epochs": 500,
      "batch_size": 4831
    },
    "evaluator_kwargs": {
      "filtered": true
    }
  },
  "results": {
    "hits_at_k": {
      "nondeterministic": {
        "1": 0.402,
        "3": 0.613,
        "10": 0.739
      }
    },
    "mean_reciprocal_rank": {
      "nondeterministic": 0.524
    }
  }
}