metadata:
  comments: ' We use same setting as for WN18 (based on https://github.com/mnick/holographic-embeddings/blob/c2db6e1554e671ab8e6acace78ec1fd91d6a4b90/run_hole_wn18.sh,
    however it is not sure whether this is the correct setting) since we couldn''t
    find the setting for FB15k. The evaluation uses the non-deterministic rank, as
    seen from https://github.com/mnick/holographic-embeddings/blob/c2db6e1554e671ab8e6acace78ec1fd91d6a4b90/kg/base.py#L198.'
  title: Learn FB15K Dataset with HolE as described by Nickel et al., 2016
pipeline:
  dataset: fb15k
  evaluator_kwargs:
    filtered: true
  loss: MarginRankingLoss
  loss_kwargs:
    margin: 0.2
    reduction: mean
  model: HolE
  model_kwargs:
    embedding_dim: 150
    entity_constrainer: clamp_norm
    entity_initializer: xavier_uniform
    relation_initializer: xavier_uniform
  negative_sampler: basic
  negative_sampler_kwargs:
    num_negs_per_pos: 1
  optimizer: AdaGrad
  optimizer_kwargs:
    lr: 0.1
  training_kwargs:
    batch_size: 4831
    num_epochs: 500
  training_loop: SLCWA
results:
  hits_at_k:
    nondeterministic:
      '1': 0.402
      '10': 0.739
      '3': 0.613
  mean_reciprocal_rank:
    nondeterministic: 0.524
