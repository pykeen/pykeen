metadata:
  title: Learn CoDEx-Large Dataset with NodePiece + RotatE (no anchor tokenization) as described by Galkin et al., 2022
pipeline:
  random_seed: 42
  dataset: codexlarge
  dataset_kwargs:
    create_inverse_triples: True
  evaluator_kwargs:
    filtered: true
  loss: BCEWithLogitsLoss
  loss_kwargs:
    reduction: 'mean'
  model: NodePiece
  model_kwargs:
    entity_initializer: xavier_uniform_
    relation_initializer: init_phases
    relation_constrainer: complex_normalize
    embedding_dim: 200   # for both anchors and relations
    interaction: RotatEInteraction
    aggregation: mlp
    tokenizers: RelationTokenizer
    num_tokens: 6  # 6 relations

  optimizer: Adam
  optimizer_kwargs:
    lr: 0.0005
  training_kwargs:
    batch_size: 256
    num_epochs: 121
    label_smoothing: 0.3
  training_loop: LCWA
results:  # https://openreview.net/pdf?id=xMJWUKJnFSw Table 3 row 6
  best:
    hits_at_k:
      '10': 0.121
    mean_reciprocal_rank: 0.063
