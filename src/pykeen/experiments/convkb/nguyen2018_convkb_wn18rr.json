{
  "metadata": {
    "title": "Learn WN18RR Data Set with ConvKB as described by Nguyen et al., 2018",
    "comments": "regularization weight is set to 0.0005, because in the paper the regularization term is multiplied with (regularization weight)/2. The evaluation is done with the optimistic rank, cf. https://github.com/daiquocnguyen/ConvKB/blob/ba02c0665a80751676289a8d5570dc420465a9ff/eval.py#L207-L236."
  },
  "pipeline": {
    "dataset": "wn18rr",
    "model": "ConvKB",
    "model_kwargs": {
      "embedding_dim": 50,
      "num_filters": 500,
      "hidden_dropout_rate": 0.0
    },
    "regularizer": "PowerSum",
    "regularizer_kwargs": {
      "apply_only_once": true,
      "weight": 0.0005,
      "p": 2.0,
      "normalize": false
    },
    "optimizer": "Adam",
    "optimizer_kwargs": {
      "lr": 0.0001
    },
    "loss": "SoftplusLoss",
    "loss_kwargs": {
      "reduction": "mean"
    },
    "training_loop": "SLCWA",
    "negative_sampler": "bernoulli",
    "negative_sampler_kwargs": {
      "num_negs_per_pos": 1
    },
    "training_kwargs": {
      "num_epochs": 200,
      "batch_size": 256
    },
    "evaluator_kwargs": {
      "filtered": true
    }
  },
  "results": {
    "mean_rank": {
      "best": 2554
    },
    "hits_at_k": {
      "best": {
        "10": 0.525
      }
    },
    "mean_reciprocal_rank": {
      "best": 0.248
    }
  }
}